# ====================== 基础配置 ======================
# 目标变量名称：你要预测的那一列的列名
target_name: "T2D"

# ====================== 特征配置 ======================
# 分类特征 (1个基础特征 + 30个生活习惯特征 = 31个)
categorical_features:
  # 基础特征
  - "f_31_0_0"    # 性别
  # 生活习惯分类特征
  - "f_1478_0_0"
  - "f_1349_0_0"
  - "f_1100_0_0"
  - "f_1628_0_0"
  - "f_1558_0_0"
  - "f_1210_0_0"
  - "f_1329_0_0"
  - "f_971_0_0"
  - "f_1110_0_0"
  - "f_20160_0_0"
  - "f_1359_0_0"
  - "f_924_0_0"
  - "f_1548_0_0"
  - "f_943_0_0"
  - "f_1170_0_0"
  - "f_2110_0_0"
  - "f_1200_0_0"
  - "f_1408_0_0"
  - "f_1369_0_0"
  - "f_1120_0_0"
  - "f_2237_0_0"
  - "f_1190_0_0"
  - "f_1249_0_0"
  - "f_1130_0_0"
  - "f_1239_0_0"
  - "f_981_0_0"
  - "f_1220_0_0"
  - "f_2634_0_0"
  - "f_1259_0_0"
  - "f_1618_0_0"

# 连续特征 (5个基础特征 + 20个生活习惯特征 = 25个)
continuous_features: 
  # 基础连续特征
  - "f_34_0_0"     # 年龄
  - "f_21022_0_0"  # BMI
  - "f_21001_0_0"  # 体重
  - "f_4079_0_0"   # 舒张压
  - "f_4080_0_0"   # 收缩压
  # 生活习惯连续特征
  - "f_2277_0_0"
  - "f_1269_0_0"
  - "f_1160_0_0"
  - "f_2139_0_0"
  - "f_1050_0_0"
  - "f_20077_0_0"
  - "f_1060_0_0"
  - "f_874_0_0"
  - "f_1309_0_0"
  - "f_1279_0_0"
  - "f_1598_0_0"
  - "f_1458_0_0"
  - "f_2149_0_0"
  - "f_914_0_0"
  - "f_1299_0_0"
  - "f_1578_0_0"
  - "f_1070_0_0"
  - "f_1319_0_0"
  - "f_1289_0_0"
  - "f_1568_0_0"

# 索引列：用于标识每条数据的唯一ID
# 如果你的数据集有ID列（如用户ID、订单ID等），就在这里指定
index_col: "f_eid"



# ====================== 数据配置 ======================
# 随机种子：确保实验可以重复
seed: 42

# 数据文件配置
data_files:
  train: "train/train_merged.csv"     # 训练文件路径
  test: "test/test_merged.csv"        # 测试文件路径

# 训练集分割配置：将训练数据分成训练集和验证集
train_test_split: 
  test_size: 0.1        # 使用10%的数据作为验证集
  shuffle: true         # 是否打乱数据顺序
  random_state: 42      # 随机种子

# 目标变量配置
target_name: "T2D"      # 目标变量的列名
#target_mapping: null    # 不需要映射时设为null
# 如果需要映射，可以这样设置：
target_mapping:
  0: 0
  1: 1

# ====================== 模型配置 ======================
# 模型类型：这里使用的是特征标记化的Transformer模型
model_class: "feature_tokenizer_transformer"
model_kwargs:
  # 模型结构参数
  output_dim: 1          # 二分类任务
  embedding_dim: 128     # 增加到128
  nhead: 8              # 增加到8
  num_layers: 3         # 增加到3
  dim_feedforward: 256  # 增加到256
  
  # MLP（多层感知机）配置
  mlp_hidden_dims:      
    - 256
    - 128
    - 64
  
  # 激活函数和正则化
  activation: 'gelu'    
  attn_dropout_rate: 0.3  # 增加dropout
  ffn_dropout_rate: 0.3   # 增加dropout

# ====================== 训练配置 ======================
# 损失函数配置
loss_function: "WeightedBCEWithLogitsLoss"  # 使用新的损失函数名
loss_kwargs:  # 可以传递参数给损失函数
  pos_weight: 5.0  # 进一步增加正类权重

# 优化器配置
optim: "adamw"                 # 优化器类型：adamw是当前最常用的优化器
optim_kwargs:
  lr: 0.0001                # 进一步降低学习率
  weight_decay: 0.001       # 增加正则化

# 学习率调度器配置：动态调整学习率
lr_scheduler: "reduce_on_plateau"  # 当性能不再提升时降低学习率
lr_scheduler_kwargs: 
  mode: "max"                 # 监控指标的模式：是越小越好还是越大越好
  factor: 0.5                 # 学习率调整因子：每次调整将学习率乘以0.5
  patience: 5                 # 容忍多少个epoch性能不提升
lr_scheduler_by_custom_metric: true  # 是否使用自定义指标来调整学习率

# 训练超参数
train_batch_size: 32       # 减小批次大小
eval_batch_size: 64        # 评估时的批次大小
epochs: 100                 # 增加训练轮数

# ====================== 训练控制 ======================
# 早停设置：防止过拟合
early_stopping: true        # 是否启用早停
early_stopping_patience: 30  # 增加耐心值
early_stopping_start_from: 30  # 延后早停开始时间

# 评估指标配置
custom_metric: "f1_score_macro"     # 使用F1分数
is_greater_better: true             # F1分数越大越好

# ====================== 输出配置 ======================
# 在原有配置的基础上添加以下内容
output_dir: "outputs"                    # 输出根目录
model_dir: "outputs/models/task1"        # 模型保存目录
save_model: true                         # 是否保存模型
save_best: true                          # 是否保存最佳模型
save_last: true                          # 是否保存最后一轮的模型
model_name: "task1_model"                # 模型文件名前缀
log_dir: "outputs/logs/task1"            # 日志保存目录
plot_dir: "outputs/plots/task1"          # 训练图表保存目录
to_submssion: true                       # 是否生成预测结果文件
submission_file: "outputs/task1_submission.csv"  # 预测结果文件名

# 处理类别不平衡
class_weights: [0.3, 0.7]   # 进一步调整类别权重